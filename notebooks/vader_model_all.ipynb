{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb902065-390d-4341-8645-a2492ba7db16",
   "metadata": {},
   "source": [
    "#Â Imports & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814ee64c-aaee-4918-bc85-8701f82f15a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e1fafa-b4ef-48cc-b364-909788e3a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 rows\n",
      "Loaded 300 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'newsletter_number', 'issue_date', 'new_theme', 'text', 'domain',\n",
       "       'organisation', 'org_group', 'year_quarter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "\n",
    "sample = pd.read_csv(\"/workspaces/ERP_Newsletter/data_processed/sample_300_full.csv\")\n",
    "labels = pd.read_csv(\"/workspaces/ERP_Newsletter/data_processed/sample_llm_prelabeled.csv\")\n",
    "\n",
    "print(f\"Loaded {len(labels)} rows\")\n",
    "print(f\"Loaded {len(sample)} rows\")\n",
    "\n",
    "sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1cdfb50-b604-4fdb-8cfb-44abfde904fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge\n",
    "labels = labels.rename(columns={\"doc_id\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcad6dc-c24a-46ba-885d-f65db8b7adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged dataset shape: (300, 12)\n",
      "Columns: ['id', 'newsletter_number', 'issue_date', 'new_theme', 'text', 'domain', 'organisation', 'org_group', 'year_quarter', 'llm_label', 'llm_confidence', 'llm_rationale']\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(sample, labels, on=[\"id\", \"text\"], how=\"inner\")\n",
    "print(f\"âœ… Merged dataset shape: {df.shape}\")\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2c5978-046e-40f4-9404-2119698f1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Columns retained: ['id', 'text', 'new_theme', 'organisation', 'org_group', 'year_quarter', 'llm_label', 'llm_confidence']\n"
     ]
    }
   ],
   "source": [
    "keep_cols = [\n",
    "    \"id\",\n",
    "    \"text\",\n",
    "    \"new_theme\",\n",
    "    \"organisation\",\n",
    "    \"org_group\",\n",
    "    \"year_quarter\",\n",
    "    \"llm_label\",\n",
    "    \"llm_confidence\"\n",
    "]\n",
    "\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "print(f\"âœ… Columns retained: {keep_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45f8ce-b0d9-4cd2-adca-0af689926f62",
   "metadata": {},
   "source": [
    "# Light Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b401ef5-5d07-4c78-af9f-6127b3689c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_for_vader'] = df['text'].fillna('')  # Ensure no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751c9f89-9043-4a43-ba11-9d1bf2eec986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove URLs \n",
    "df['text_for_vader'] = df['text_for_vader'].str.replace(\n",
    "    r'http\\S+|www\\S+', '', regex=True\n",
    ").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272f8b47-f67f-40ba-b932-d247c3e7a5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    300.000000\n",
      "mean      42.133333\n",
      "std       21.375029\n",
      "min        6.000000\n",
      "25%       26.000000\n",
      "50%       37.000000\n",
      "75%       52.000000\n",
      "max      125.000000\n",
      "Name: text_for_vader, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check text lengths (VADER works better on sentences/paragraphs)\n",
    "print(df['text_for_vader'].str.split().str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc1775d-0c4e-4237-9436-c2c813be5f52",
   "metadata": {},
   "source": [
    "# VADER MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26241464-7fa3-4e23-85c9-a4556c33accf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Applying VADER to full dataset (n=300)...\n",
      "âœ… Saved complete dataset with VADER scores â†’ /workspaces/ERP_Newsletter/data_processed/full_dataset_with_vader.csv\n",
      "\n",
      "ðŸ“Š Sample VADER Results:\n",
      "                                     id  \\\n",
      "0  1b109222-dc42-4d14-92fc-c60320f919f7   \n",
      "1  7991db15-4956-4f31-901e-a5957934fafa   \n",
      "2  914f2011-717a-400c-9e22-a4463f2b3f07   \n",
      "3  e5fcb0b3-f40f-435f-9c52-e357ce815ff0   \n",
      "4  a0a05c90-af1c-4671-8fdc-bcaab4aac7fc   \n",
      "5  4d566bdd-bb9c-4e83-beda-13171ae20bc0   \n",
      "6  02a26253-a12d-457a-bf1c-7ac8c734b751   \n",
      "7  d0bd333a-f888-442c-9bf7-41c64e22d345   \n",
      "8  58ead779-ad80-492b-844e-00bfd566990e   \n",
      "9  be4fe8a5-4b5f-41d6-9de2-4e8df14f5b47   \n",
      "\n",
      "                                                text llm_label  \\\n",
      "0  FCDO - Foreign Secretary to call for internati...   neutral   \n",
      "1  ChatGPT isn't the death of homework â€“ just an ...  positive   \n",
      "2  DfE - Generative AI in education: educator and...   neutral   \n",
      "3  Ofsted Statement - How Ofsted looks at AI duri...   neutral   \n",
      "4  DfE Consultation - Narrowing the digital divid...   neutral   \n",
      "5  DfE - AI revolution to give teachers more time...  positive   \n",
      "6  Ofsted has published its approach to AI. Ofste...   neutral   \n",
      "7  Sir Martyn Oliver's speech to Parentkind Sir M...   neutral   \n",
      "8  Meet the founders of 'revolutionary' AI being ...   neutral   \n",
      "9  DfE moves ahead with e-register plan amid atte...   neutral   \n",
      "\n",
      "   vader_compound vader_label  \n",
      "0          0.3400    positive  \n",
      "1          0.8921    positive  \n",
      "2          0.0516    positive  \n",
      "3          0.0000     neutral  \n",
      "4          0.2500    positive  \n",
      "5          0.9186    positive  \n",
      "6          0.8588    positive  \n",
      "7         -0.2263    critical  \n",
      "8         -0.4767    critical  \n",
      "9          0.0000     neutral  \n",
      "\n",
      "ðŸ“ˆ VADER Label Distribution:\n",
      "vader_label\n",
      "positive    156\n",
      "critical     81\n",
      "neutral      63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“ˆ LLM Label Distribution:\n",
      "llm_label\n",
      "neutral     213\n",
      "critical     48\n",
      "positive     39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# VADER Model \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(df, text_col=\"text_for_vader\"):\n",
    "    \"\"\"Apply VADER sentiment and return dataframe with scores and labels\"\"\"\n",
    "    def get_scores(text):\n",
    "        scores = analyzer.polarity_scores(str(text))\n",
    "        return pd.Series({\n",
    "            \"vader_neg\": scores[\"neg\"],\n",
    "            \"vader_neu\": scores[\"neu\"],\n",
    "            \"vader_pos\": scores[\"pos\"],\n",
    "            \"vader_compound\": scores[\"compound\"]\n",
    "        })\n",
    "    \n",
    "    vader_scores = df[text_col].apply(get_scores)\n",
    "    df = df.join(vader_scores)\n",
    "    \n",
    "    df[\"vader_label\"] = df[\"vader_compound\"].apply(\n",
    "        lambda c: \"positive\" if c >= 0.05 else (\"critical\" if c <= -0.05 else \"neutral\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply VADER to entire dataset\n",
    "print(f\"\\nðŸ”„ Applying VADER to full dataset (n={len(df)})...\")\n",
    "df_with_vader = get_vader_sentiment(df, text_col=\"text_for_vader\")\n",
    "\n",
    "# Save complete scored dataset\n",
    "output_path = \"/workspaces/ERP_Newsletter/data_processed/full_dataset_with_vader.csv\"\n",
    "df_with_vader.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Saved complete dataset with VADER scores â†’ {output_path}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nðŸ“Š Sample VADER Results:\")\n",
    "print(df_with_vader[[\"id\", \"text\", \"llm_label\", \"vader_compound\", \"vader_label\"]].head(10))\n",
    "\n",
    "# Quick distribution check\n",
    "print(f\"\\nðŸ“ˆ VADER Label Distribution:\")\n",
    "print(df_with_vader[\"vader_label\"].value_counts())\n",
    "print(f\"\\nðŸ“ˆ LLM Label Distribution:\")\n",
    "print(df_with_vader[\"llm_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edadc00-4ef2-4618-896d-12a970d43632",
   "metadata": {},
   "source": [
    "# Evaluate Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b23c31-86b1-4ef9-9e15-e7526897bf26",
   "metadata": {},
   "source": [
    "# Diagnostics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2bf44d-4472-48b3-a1bc-0ce7fe93ac56",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab2b74-bf22-44f7-95bc-3f48c2db409a",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e0204-60aa-41b4-b0fc-36de4e6df373",
   "metadata": {},
   "source": [
    "### Precision-Recall by Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0540aa4-24eb-4135-84be-a5379d8dbccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
